{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "from sklearn.utils import shuffle\n",
    "from collections import OrderedDict\n",
    "from shutil import copyfile\n",
    "\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model \n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras import backend as k \n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ensure GPU\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check dim ordering\n",
    "print(k.image_data_format())#integer seed for any randomnessnp.int64(np.floor(time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize session\n",
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# Some tensor we want to print the value of\n",
    "a = tf.constant([1.0, 3.0])\n",
    "\n",
    "# Add print operation\n",
    "a = tf.Print(a, [a], message=\"This is a: \")\n",
    "\n",
    "# Add more elements of the graph using a\n",
    "b = tf.add(a, a).eval()\n",
    "Now, whenever we evaluate the whole graph, e.g. using b.eval(), we get:\n",
    "\n",
    "I tensorflow/core/kernels/logging_ops.cc:79] This is a: [1 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bosch_label_dict = {\n",
    "    'red': [],\n",
    "    'yellow': [],\n",
    "    'green': [],\n",
    "    'nolight': []\n",
    "}\n",
    "\n",
    "label_set = set(['red', 'green', 'yellow'])\n",
    "for image in data_yaml:\n",
    "    if len(image['boxes']) > 5:\n",
    "        continue\n",
    "    elif not image['boxes']:\n",
    "        bosch_label_dict['nolight'].append(image['path'])\n",
    "    else:\n",
    "        image_labels = Counter([x['label'].lower() for x in image['boxes'] if x['label'].lower() in bosch_label_dict])\n",
    "        if len(image_labels.most_common()) > 0:\n",
    "            chosen_label = image_labels.most_common()[0][0]\n",
    "            bosch_label_dict[chosen_label].append(image['path'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir = './data/bosch_traffic/full_set/'\n",
    "if not os.path.exists(working_dir): os.mkdir(working_dir)\n",
    "for label, files in bosch_label_dict.items():\n",
    "    label_dir = working_dir + label\n",
    "    if not os.path.exists(label_dir): os.mkdir(label_dir)\n",
    "    for file in files:\n",
    "        shutil.copy2('./data/bosch_traffic/' + file, label_dir + '/' + os.path.basename(os.path.normpath(file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_data_dir_for_keras(seed, data_base_uri):\n",
    "    data_dir = os.getcwd() + data_base_uri\n",
    "    full_data_dir = data_dir + 'full_set/'\n",
    "    working_data_dir = data_dir + 'working_set/'\n",
    "\n",
    "    if not os.path.exists(working_data_dir): os.mkdir(working_data_dir)\n",
    "        \n",
    "    for subset_label in ['train/', 'val/', 'test/']:\n",
    "        subset_data_uri = working_data_dir + subset_label\n",
    "        if not os.path.exists(subset_data_uri): os.mkdir(subset_data_uri)\n",
    "\n",
    "    for class_name in os.listdir(full_data_dir):\n",
    "        for subset_label in ['train/', 'val/', 'test/']:\n",
    "            subset_label_data_uri = working_data_dir + subset_label + class_name + '/'\n",
    "            if not os.path.exists(subset_label_data_uri): os.mkdir(subset_label_data_uri)\n",
    "        D_class = []\n",
    "        \n",
    "        for filename in glob.glob(full_data_dir + class_name + '/*.png'):\n",
    "            D_class.append(filename)\n",
    "\n",
    "        D_class = shuffle(D_class, random_state=seed)\n",
    "    \n",
    "        class_count = len(D_class)\n",
    "        train_val_index = int(np.floor(len(D_class) * 0.70))\n",
    "        val_test_index = int(np.floor(len(D_class) * 0.85))\n",
    "\n",
    "        # can be abbreviated considerably\n",
    "        for file in D_class[:train_val_index]:\n",
    "            shutil.copy2(file, \n",
    "                         working_data_dir + '/train/' + class_name + '/' + os.path.basename(os.path.normpath(file)))\n",
    "        for file in D_class[train_val_index:val_test_index]:\n",
    "            shutil.copy2(file, \n",
    "                         working_data_dir + '/val/' + class_name + '/' + os.path.basename(os.path.normpath(file)))\n",
    "        for file in D_class[val_test_index:]:\n",
    "            shutil.copy2(file, \n",
    "                         working_data_dir + '/test/' + class_name + '/' + os.path.basename(os.path.normpath(file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.getcwd() + '/data/final_sim_data'\n",
    "full_data_dir = data_dir + '/full_set'\n",
    "working_data_dir = data_dir + '/working_set'\n",
    "\n",
    "\n",
    "\n",
    "for class_name in os.listdir(full_data_dir):\n",
    "    D_class = []\n",
    "    \n",
    "    for filename in glob.glob(full_data_dir + '/' + class_name + '/*.png'):\n",
    "        D_class += filename\n",
    "    \n",
    "    D_class = shuffle(np.array(D_class))\n",
    "    \n",
    "    class_count = len(D_class)\n",
    "    train_val_index = int(np.floor(len(D_class) * 0.70))\n",
    "    val_test_index = int(np.floor(len(D_class) * 0.85))\n",
    "Contents\n",
    "    for file in D_class[:train_val_index]:\n",
    "        shutil.copy2(filename, \n",
    "                     working_data_dir + '/train/' + class_name + os.path.basename(os.path.normpath(filename)))\n",
    "    for file in D_class[train_val_index:val_test_index]:\n",
    "        shutil.copy2(filename, \n",
    "                     working_data_dir + '/val/' + class_name + os.path.basename(os.path.normpath(filename)))\n",
    "    for file in D_class[val_test_index:]:\n",
    "        shutil.copy2(filename, \n",
    "                     working_data_dir + '/test/' + class_name + os.path.basename(os.path.normpath(filename)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VISUALIZTION TECHNIQUES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T-SNE conversion to lower dimensions with grid arranged viewing\n",
    "\n",
    "## Maximal activation of kernels (hottest images)\n",
    "\n",
    "## Visualize filters, look for smoothness (maybe even autocalculate it) -> training duration and overfitting\n",
    "\n",
    "## activation maps of images -> find dead filters, also automatically\n",
    "\n",
    "## occulsion probability heatmaps -> see what's really learning the class in the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TENSOR BOARD SHIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper stolen \n",
    "def get_nb_files(directory):\n",
    "  \"\"\"Get number of files by searching directory recursively\"\"\"\n",
    "  if not os.path.exists(directory):\n",
    "    return 0\n",
    "  cnt = 0\n",
    "  for r, dirs, files in os.walk(directory):\n",
    "    for dr in dirs:\n",
    "      cnt += len(glob.glob(os.path.join(r, dr + \"/*\")))\n",
    "  return cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a bunch of junk code for pushing around earlier data that I'm not sure I won't need again...\n",
    "\n",
    "# find . -type f -name '*.png' -delete\n",
    "\n",
    "# !! ls data/TrafficLightDataset/working_data/\n",
    "\n",
    "# with open('./data/TrafficLightDataset/labels_num.csv') as labels:\n",
    "#     c_labels = OrderedDict(csv.reader(labels))\n",
    "\n",
    "# X_labels = np.array(list(c_labels.keys()))\n",
    "# Y = np.array(list(c_labels.values()))\n",
    "# shuffle(X_labels, Y)\n",
    "\n",
    "# images = []\n",
    "# for label in X_labels:\n",
    "#     loc = \"/home/dieslow/WORKSPACE/PROJECTS/CARZ/nanodegree/Capstone/ros/src/tl_detector/data/TrafficLightDataset/image_data/\" + label + \".png\"\n",
    "#     image = cv2.imread(loc, 1)\n",
    "# #     image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB) \n",
    "#     # May not need to do resizing... BUT SHOULD VIEW IMAGES\n",
    "# #     resized_image = cv2.resize(image, (256, 256)) \n",
    "#     images.append(image)\n",
    "# X = np.array(images)\n",
    "# print(X.shape)\n",
    "\n",
    "# train_val_index = int(np.floor(len(Y) * 0.85))\n",
    "\n",
    "# D = list(zip(X, Y))\n",
    "# D_train = D[:train_val_index]\n",
    "# D_val = D[train_val_index:]\n",
    "# X_train, Y_train = zip(*D_train)\n",
    "# print(len(X_train))\n",
    "# X_val, Y_val = zip(*D_val)\n",
    "# print(len(X_val))\n",
    "\n",
    "# images = []\n",
    "# for x, y in D_train:\n",
    "#     loc = \"/home/dieslow/WORKSPACE/PROJECTS/CARZ/nanodegree/\" + \\\n",
    "#           \"Capstone/ros/src/tl_detector/data/TrafficLightDataset/working_data/train/\" + \\\n",
    "#           str(y) + \"/\" + str(np.random.randint(100000000, 999999999)) + \".png\"\n",
    "#     cv2.imwrite(loc, x)\n",
    "    \n",
    "# for x, y in D_val:\n",
    "#     loc = \"/home/dieslow/WORKSPACE/PROJECTS/CARZ/nanodegree/\" + \\\n",
    "#           \"Capstone/ros/src/tl_detector/data/TrafficLightDataset/working_data/val/\" + \\\n",
    "#           str(y) + \"/\" + str(np.random.randint(100000000, 999999999)) + \".png\"\n",
    "#     cv2.imwrite(loc, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BASIC TEMPLATE  FOR TRANSFER LEARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT, IMG_WIDTH = 299, 299\n",
    "\n",
    "# TRAIN_DATA_DIR = \"data/TrafficLightDataset/working_data/train\"\n",
    "# VAL_DATA_DIR = \"data/TrafficLightDataset/working_data/val\"\n",
    "TRAIN_DATA_DIR = \"./data/TrafficLightDataset/big_working_data/train\"\n",
    "VAL_DATA_DIR = \"./data/TrafficLightDataset/big_working_data/val\"\n",
    "TEST_DATA_DIR = \"./data/TrafficLightDataset/big_working_data/test\"\n",
    "\n",
    "NB_TRAIN_SAMPLES = get_nb_files(TRAIN_DATA_DIR)\n",
    "NB_VAL_SAMPLES = get_nb_files(VAL_DATA_DIR)\n",
    "NB_TEST_SAMPLES = get_nb_files(TEST_DATA_DIR)\n",
    "\n",
    "BATCH_SIZE = 40\n",
    "EPOCHS_TRANSFER = 5\n",
    "EPOCHS_FINE_TUNE = 5\n",
    "\n",
    "TRAIN_STEPS_PER_EPOCH = int(np.ceil(NB_TRAIN_SAMPLES / BATCH_SIZE))\n",
    "VAL_STEPS_PER_EPOCH = int(np.ceil(NB_VAL_SAMPLES / BATCH_SIZE))\n",
    "TEST_STEPS_PER_EPOCH = int(np.ceil(NB_TEST_SAMPLES / BATCH_SIZE))\n",
    "\n",
    "FROZEN_LAYERS = 172\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USE TF COLLECTIONS FOR KEY VALUE GROUPED METADATA LIKE LOSS COMPONENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IN TF AN EDGE IS A TENSOR AND A NODE IS A OPERATION!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FOR LOADING AND SAVING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "saver = tf.train.Saver()    \n",
    "saver.save(sess, './models/workingish_beta_1.0')\n",
    "# OPTIONAL: Apply the trained model to a video\n",
    "\n",
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    saver = tf.train.import_meta_graph('my_test_model-1000.meta')\n",
    "#     loader = tf.train.Saver()\n",
    "    saver.restore(sess, './models/checkpoint')\n",
    "    \n",
    "    graph = tf.get_default_graph()\n",
    "    w1 = graph.get_tensor_by_name(\"w1:0\")\n",
    "    w2 = graph.get_tensor_by_name(\"w2:0\")\n",
    "    feed_dict ={w1:13.0,w2:17.0}\n",
    "\n",
    "    #Now, access the op that you want to run. \n",
    "    op_to_restore = graph.get_tensor_by_name(\"op_to_restore:0\")\n",
    "\n",
    "print sess.run(op_to_restore,feed_dict)\n",
    "#This will print 60 which is calculated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate the train and test generators with data Augumentation \n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "#     rescale = 1./255,\n",
    "#     horizontal_flip = True,\n",
    "#     zoom_range = 0.4,\n",
    "#     width_shift_range = 0.3,\n",
    "#     height_shift_range=0.3,\n",
    "#     rotation_range=20\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "#     horizontal_flip = True,\n",
    "#     rescale = 1./255,\n",
    "#     fill_mode = \"nearest\"\n",
    "#     zoom_range = 0.3,\n",
    "#     width_shift_range = 0.3,\n",
    "#     height_shift_range=0.3,\n",
    "#     rotation_range=30\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    TRAIN_DATA_DIR,\n",
    "    target_size = (IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size = BATCH_SIZE)\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    VAL_DATA_DIR,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    target_size = (IMG_HEIGHT, IMG_WIDTH))\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    VAL_DATA_DIR,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    target_size = (IMG_HEIGHT, IMG_WIDTH))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape = (IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "\n",
    "# + global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# + FC layer\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "\n",
    "# + log laye\n",
    "predictions = Dense(4, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# freeze all convolutional layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model (most places, including the inceptv3 paper recommended RMSProp, \n",
    "#  but I had a lot of premature convergence issues with it. to be fair, I switched to\n",
    "#  adam experimenting around before I spent anytime optimizing LR, so who knows. converges\n",
    "#  quick enough for Anand's data as it is)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Save the model according to the conditions  \n",
    "checkpoint = ModelCheckpoint(\"inceptionv3.h5\", monitor='val_loss', verbose=1, save_best_only=True, \n",
    "                             save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, mode='auto')\n",
    "\n",
    "# training for transfer learning\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = TRAIN_STEPS_PER_EPOCH,\n",
    "    epochs = EPOCHS_TRANSFER,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps = VAL_STEPS_PER_EPOCH,\n",
    "    callbacks = [early, checkpoint],\n",
    "    verbose=True, \n",
    "    class_weight='auto',\n",
    "    use_multiprocessing=True)\n",
    "\n",
    "# start fine-tuning conv layers in addition to FC. \n",
    "# freeze the bottom FROZEN_LAYERS layers, train the rest\n",
    "for layer in model.layers[:FROZEN_LAYERS]:\n",
    "   layer.trainable = False\n",
    "for layer in model.layers[FROZEN_LAYERS:]:\n",
    "   layer.trainable = True\n",
    "\n",
    "# compile\n",
    "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# training for fine-tuning conv layers\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = TRAIN_STEPS_PER_EPOCH,\n",
    "    epochs = EPOCHS_FINE_TUNE,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps = VAL_STEPS_PER_EPOCH,\n",
    "    callbacks = [early, checkpoint], #\n",
    "    verbose=True,\n",
    "    class_weight='auto',\n",
    "    use_multiprocessing=True)\n",
    "\n",
    "\n",
    "print(model.metrics_names)\n",
    "model.evaluate_generator(\n",
    "    test_generator,\n",
    "    steps = TEST_STEPS_PER_EPOCH,\n",
    "    use_multiprocessing=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
